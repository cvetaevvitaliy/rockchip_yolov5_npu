{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MPjfT5NrKQ"
   },
   "source": [
    "<a align=\"left\" href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
    "<img width=\"1024\", src=\"https://user-images.githubusercontent.com/26833433/125273437-35b3fc00-e30d-11eb-9079-46f313325424.png\"></a>\n",
    "\n",
    "This is the **official YOLOv5 ðŸš€ notebook** by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
    "For more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Clone repo, install dependencies and check PyTorch and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "185d0979-edcd-4860-e6fb-b8a27dbf5096"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 32b94fb torch 1.12.0+cu116 CUDA:0 (NVIDIA GeForce RTX 3090 Ti, 24248MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete âœ… (24 CPUs, 62.6 GB RAM, 286.1/914.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/cvetaevvitaliy/rockchip_yolov5_npu  # clone\n",
    "#%cd rockchip_yolov5_npu/yolov5\n",
    "#%pip install -qr requirements.txt  # install\n",
    "\n",
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 32b94fb torch 1.12.0+cu116 CUDA:0 (NVIDIA GeForce RTX 3090 Ti, 24248MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete âœ… (24 CPUs, 62.6 GB RAM, 286.1/914.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY2VXXXu74w5"
   },
   "source": [
    "# 3. Train\n",
    "\n",
    "<p align=\"\"><a href=\"https://roboflow.com/?ref=ultralytics\"><img width=\"1000\" src=\"https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png\"/></a></p>\n",
    "Close the active learning loop by sampling images from your inference conditions with the `roboflow` pip package\n",
    "<br><br>\n",
    "\n",
    "Train a YOLOv5s model on the [COCO128](https://www.kaggle.com/ultralytics/coco128) dataset with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`.\n",
    "\n",
    "- **Pretrained [Models](https://github.com/ultralytics/yolov5/tree/master/models)** are downloaded\n",
    "automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)\n",
    "- **[Datasets](https://github.com/ultralytics/yolov5/tree/master/data)** available for autodownload include: [COCO](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml), [COCO128](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml), [VOC](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml), [Argoverse](https://github.com/ultralytics/yolov5/blob/master/data/Argoverse.yaml), [VisDrone](https://github.com/ultralytics/yolov5/blob/master/data/VisDrone.yaml), [GlobalWheat](https://github.com/ultralytics/yolov5/blob/master/data/GlobalWheat2020.yaml), [xView](https://github.com/ultralytics/yolov5/blob/master/data/xView.yaml), [Objects365](https://github.com/ultralytics/yolov5/blob/master/data/Objects365.yaml), [SKU-110K](https://github.com/ultralytics/yolov5/blob/master/data/SKU-110K.yaml).\n",
    "- **Training Results** are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=../dataset/data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=50, batch_size=-1, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=True, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=military, name=train_05-02-2023_0, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 ðŸš€ 32b94fb torch 1.12.0+cu116 CUDA:0 (NVIDIA GeForce RTX 3090 Ti, 24248MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir military', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 1280\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 3090 Ti) 23.68G total, 0.10G reserved, 0.08G allocated, 23.50G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     7027720       63.85         0.679         22.61          15.9      (1, 3, 1280, 1280)                    list\n",
      "     7027720       127.7         1.365         9.986         16.82      (2, 3, 1280, 1280)                    list\n",
      "     7027720       255.4         2.512         15.59         23.71      (4, 3, 1280, 1280)                    list\n",
      "     7027720       510.8         4.834         30.64         44.72      (8, 3, 1280, 1280)                    list\n",
      "     7027720        1022         9.586         61.64         85.06     (16, 3, 1280, 1280)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 35 for CUDA:0 21.31G/23.68G (90%)\n",
      "Scaled weight_decay = 0.000546875\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../dataset/train/tank4/labels.cache' images and labels... 21576\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../dataset/train/task159/images/001.png: 4 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../dataset/train/task48/images/007.png: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../dataset/valid/tank4/labels.cache' images and labels... 3510 fo\u001b[0m\n",
      "Plotting labels to military/train_05-02-2023_04/labels.jpg... \n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mmilitary/train_05-02-2023_04\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/49     21.4G   0.06809    0.0607   0.01214       168      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.521      0.555      0.522      0.232\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/49     18.6G    0.0495   0.05181  0.003363       180      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.538      0.588      0.579      0.277\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/49     18.6G   0.04745    0.0503  0.002985       170      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.637      0.542      0.575       0.28\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/49     18.6G   0.04235   0.04916  0.002375       177      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.687      0.642      0.673      0.353\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      4/49     21.5G   0.03914   0.04616  0.001792       196      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.659      0.637       0.67      0.353\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      5/49     21.5G   0.03787   0.04507   0.00161        79      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.708      0.654      0.713      0.389\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      6/49     21.5G   0.03671   0.04383  0.001407       138      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726       0.71      0.681      0.725      0.395\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      7/49     21.5G   0.03568   0.04269    0.0013       171      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.704      0.697       0.74      0.409\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      8/49     21.5G   0.03514   0.04192  0.001216       207      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.701      0.704      0.745       0.42\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      9/49     21.5G   0.03426   0.04115  0.001153       207      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.707      0.693      0.744       0.42\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     10/49     21.5G   0.03401   0.04109  0.001064       147      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.755      0.728      0.782       0.44\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     11/49     21.5G   0.03378   0.04042  0.001083       169      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.712      0.709      0.756      0.424\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     12/49     21.5G   0.03324   0.03974  0.001034       178      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.748      0.724      0.774      0.438\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     13/49     21.5G   0.03304   0.04008 0.0009543       163      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.746      0.734      0.784      0.456\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     14/49     21.5G   0.03245   0.03865 0.0009101       173      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.739      0.746      0.789      0.461\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     15/49     21.5G   0.03223   0.03861 0.0008792       200      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.774      0.736      0.796       0.47\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     16/49     21.5G   0.03205   0.03792 0.0008956       126      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.773      0.736      0.799      0.471\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     17/49     21.5G   0.03166   0.03783 0.0008823       187      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.777      0.739      0.804      0.473\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     18/49     21.5G   0.03116   0.03754 0.0008632       169      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.775      0.749      0.806       0.48\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     19/49     21.5G    0.0312   0.03692 0.0007805       145      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.777      0.749      0.809      0.482\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     20/49     21.5G   0.03081   0.03652 0.0007655       156      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.768      0.755      0.808      0.484\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     21/49     21.5G   0.03069   0.03616 0.0007641       123      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.792      0.749      0.815      0.488\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     22/49     21.5G   0.03028   0.03587 0.0007125       136      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.784      0.771      0.819      0.496\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     23/49     21.5G   0.03019   0.03566 0.0007289       207      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.774      0.781      0.821      0.501\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     24/49     21.5G   0.02978   0.03521 0.0006957       123      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.781      0.787      0.824        0.5\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     25/49     21.5G   0.02969   0.03499 0.0006884       175      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.794      0.762      0.822      0.505\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     26/49     21.5G   0.02945   0.03503  0.000627       174      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.792      0.775      0.825      0.505\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     27/49     21.5G   0.02915   0.03474 0.0006384       207      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.803      0.769      0.826      0.507\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     28/49     21.5G   0.02916   0.03436 0.0006192        84      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.781      0.785      0.827      0.508\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     29/49     21.5G   0.02862   0.03392 0.0006122       237      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.802      0.761      0.826       0.51\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     30/49     21.5G    0.0284   0.03333 0.0006168       170      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.772      0.785      0.825      0.512\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     31/49     21.5G   0.02833   0.03338 0.0005531       293      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726       0.79      0.779       0.83      0.516\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     32/49     21.5G   0.02813   0.03335 0.0005543       192      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.786      0.784       0.83      0.517\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     33/49     21.5G   0.02789   0.03275 0.0005473       139      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.793      0.779      0.829      0.518\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     34/49     21.5G   0.02758    0.0322 0.0005396       108      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.804      0.771      0.831       0.52\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     35/49     21.5G   0.02745    0.0324 0.0005079       150      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.808       0.77      0.833       0.52\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     36/49     21.5G   0.02713   0.03204 0.0005129       188      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.822      0.761      0.834      0.524\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     37/49     21.5G   0.02702   0.03209 0.0004687       241      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.802      0.783      0.835      0.525\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     38/49     21.5G   0.02707   0.03163 0.0005183       206      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.811      0.775      0.835      0.526\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     39/49     21.5G   0.02665   0.03142  0.000463       157      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726       0.81      0.778      0.834      0.525\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     40/49     21.5G   0.02641   0.03115 0.0004482       129      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.819      0.775      0.836      0.526\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     41/49     21.5G   0.02649   0.03067 0.0004532       258      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.806      0.785      0.836      0.527\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     42/49     21.5G   0.02601    0.0307 0.0004318       185      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.797      0.795      0.836      0.528\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     43/49     21.5G   0.02622   0.03048 0.0004253       222      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726       0.81      0.781      0.837      0.529\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     44/49     21.5G   0.02606   0.03041 0.0004163       149      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726       0.79      0.797      0.837      0.529\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     45/49     21.5G    0.0257   0.02981 0.0003965       150      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.792      0.795      0.836      0.529\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     46/49     21.5G   0.02603   0.03023 0.0003933       155      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.786      0.801      0.835      0.529\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     47/49     21.5G   0.02553   0.02958 0.0003811       222      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.786      0.801      0.835      0.529\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     48/49     21.5G   0.02574   0.02965 0.0003837       115      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.794      0.795      0.835      0.529\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "     49/49     21.5G   0.02537   0.02918 0.0003747       152      1280: 100%|â–ˆâ–ˆâ–ˆ\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.794      0.794      0.835       0.53\n",
      "\n",
      "50 epochs completed in 4.112 hours.\n",
      "Optimizer stripped from military/train_05-02-2023_04/weights/last.pt, 14.7MB\n",
      "Optimizer stripped from military/train_05-02-2023_04/weights/best.pt, 14.7MB\n",
      "\n",
      "Validating military/train_05-02-2023_04/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       3510      19726      0.795      0.794      0.835       0.53\n",
      "                Tank       3510       1599      0.833      0.851      0.884      0.565\n",
      "              Person       3510       7794      0.747      0.662      0.735      0.388\n",
      "                 Car       3510      10333      0.804      0.868      0.886      0.637\n",
      "Results saved to \u001b[1mmilitary/train_05-02-2023_04\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv5s\n",
    "    # --cache \\  \n",
    "!python train.py --img 1280 --batch -1 --epochs 50 \\\n",
    "    --data '../dataset/data.yaml' \\\n",
    "    --cfg yolov5s.yaml \\\n",
    "    --weights yolov5s.pt \\\n",
    "    --noautoanchor \\\n",
    "    --project 'military' --name train_$(date +'%d-%m-%Y_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "bce1b4bd-1a14-4c07-aebd-6c11e91ad24b"
   },
   "outputs": [],
   "source": [
    "# Tune hyperparameter\n",
    "    # --cache \\\n",
    "!python train.py --img 1280 --batch -1 --epochs 50 \\\n",
    "    --data '../dataset/data.yaml' \\\n",
    "    --cfg yolov5s.yaml \\\n",
    "    --weights yolov5s.pt \\\n",
    "    --noautoanchor \\\n",
    "    --project 'military' --name 'feature_extraction' \\\n",
    "    --evolve 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with hyperparameter\n",
    "# --weights yolov5s.pt \\\n",
    "# --weights 'military/feature_extraction/weights/best.pt' \\\n",
    "!python train.py --img 1280  \\\n",
    "    --noautoanchor \\\n",
    "    --hyp './runs/evolve/feature_extraction2/hyp_evolve.yaml' --batch -1 --epochs 100 \\\n",
    "    --data '../dataset/data.yaml' \\\n",
    "    --weights yolov5s.pt \\\n",
    "    --project 'military' --name 'fine-tuning'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model \n",
    "!python detect.py \\\n",
    "    --weights 'military/train_05-02-2023_04/weights/best.pt' \\\n",
    "    --source 4 \\\n",
    "    --view-img \\\n",
    "    --img 1280  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python val.py \\\n",
    "    --task test \\\n",
    "    --weights 'military/train_2023-02-02-202/weights/best.pt' \\\n",
    "    --data '../dataset/data.yaml' \\\n",
    "    --img 1280 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model \n",
    "!python detect.py \\\n",
    "    --weights 'military/train_05-02-2023_04/weights/best.pt' \\\n",
    "    --source '/home/nacuk/1234.mov' \\\n",
    "    --view-img \\\n",
    "    --img 1280   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model \n",
    "!python detect.py \\\n",
    "    --weights 'military/train_04-02-2023_0/weights/best.pt' \\\n",
    "    --source '/home/nacuk/PM33.mp4' \\\n",
    "    --view-img \\\n",
    "    --img 1280   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model \n",
    "!python detect.py \\\n",
    "    --weights 'military/train_2023-02-02-21h/weights/best.pt' \\\n",
    "    --source '/media/ssd/video-from-ssd/2023-01-05/PM1.mp4' \\\n",
    "    --view-img \\\n",
    "    --img 1280    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model to Rockchip RKNN NPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['military/train_05-02-2023_04/weights/best.pt'], imgsz=[1280, 736], batch_size=1, device=cpu, half=False, inplace=False, train=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx'], rknpu=RK3588\n",
      "YOLOv5 ðŸš€ 32b94fb torch 1.12.0+cu116 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "---> save anchors for RKNN\n",
      "[[10.0, 13.0], [16.0, 30.0], [33.0, 23.0], [30.0, 61.0], [62.0, 45.0], [59.0, 119.0], [116.0, 90.0], [156.0, 198.0], [373.0, 326.0]]\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from military/train_05-02-2023_04/weights/best.pt (14.7 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 1.12.0+cu116...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success, saved as military/train_05-02-2023_04/weights/best.torchscript (28.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.9.0...\n",
      "/home/nacuk/virtual-yolov5/rockchip_yolov5_npu/yolov5/models/yolo.py:131: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if augment:\n",
      "/home/nacuk/virtual-yolov5/rockchip_yolov5_npu/yolov5/models/yolo.py:154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if profile:\n",
      "/home/nacuk/virtual-yolov5/rockchip_yolov5_npu/yolov5/models/yolo.py:158: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if visualize:\n",
      "/home/nacuk/virtual-yolov5/rockchip_yolov5_npu/yolov5/models/yolo.py:158: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if visualize:\n",
      "/home/nacuk/virtual-yolov5/rockchip_yolov5_npu/yolov5/models/yolo.py:154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if profile:\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success, saved as military/train_05-02-2023_04/weights/best.onnx (28.1 MB)\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m run --dynamic ONNX model inference with: 'python detect.py --weights military/train_05-02-2023_04/weights/best.onnx'\n",
      "\n",
      "Export complete (1.82s)\n",
      "Results saved to \u001b[1m/home/nacuk/virtual-yolov5/rockchip_yolov5_npu/yolov5/military/train_05-02-2023_04/weights\u001b[0m\n",
      "Visualize with https://netron.app\n"
     ]
    }
   ],
   "source": [
    "# Export model to RK3488 NPU\n",
    "!python export.py --weights 'military/train_05-02-2023_04/weights/best.pt' \\\n",
    "    --imgsz 1280 736 --batch 1 --rknpu RK3588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Source file name: military/train_05-02-2023_04/weights/best.onnx\n",
      "--> RKNN file name: rknn_models/military/train_05-02-2023_04/weights/best.rknn\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33m__init__: rknn-toolkit2 version: 1.4.0-22dcfef4\u001b[0m\n",
      "--> Loading model\n",
      "done\n",
      "--> Building model\n",
      "Analysing : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:00<00:00, 6340.39it/s]\n",
      "Quantizating : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142/142 [00:01<00:00, 103.71it/s]\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33mbuild: The default input dtype of 'images' is changed from 'float32' to 'int8' in rknn model for performance!\n",
      "                      Please take care of this change when deploy rknn model with Runtime API!\u001b[0m\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33mbuild: The default output dtype of 'output' is changed from 'float32' to 'int8' in rknn model for performance!\n",
      "                      Please take care of this change when deploy rknn model with Runtime API!\u001b[0m\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33mbuild: The default output dtype of '273' is changed from 'float32' to 'int8' in rknn model for performance!\n",
      "                      Please take care of this change when deploy rknn model with Runtime API!\u001b[0m\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33mbuild: The default output dtype of '274' is changed from 'float32' to 'int8' in rknn model for performance!\n",
      "                      Please take care of this change when deploy rknn model with Runtime API!\u001b[0m\n",
      "done\n",
      "--> Export rknn model\n",
      "export done\n"
     ]
    }
   ],
   "source": [
    "# Convert model to rknn format\n",
    "!python onnx2rknn.py 'military/train_05-02-2023_04/weights/best.onnx' 'military/train_05-02-2023_04/weights/best.rknn'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy to device via ssh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root@192.168.2.232's password: \n"
     ]
    }
   ],
   "source": [
    "!scp runs/train/exp51/weights/best.rknn root@192.168.2.232:/root/best1280.rknn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEijrePND_2I"
   },
   "source": [
    "# Appendix\n",
    "\n",
    "Additional content below for PyTorch Hub, CI, reproducing results, profiling speeds, VOC training, classification training and TensorRT example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMusP4OAxFu6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# PyTorch Hub Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom\n",
    "\n",
    "# Images\n",
    "img = 'https://ultralytics.com/images/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n",
    "\n",
    "# Inference\n",
    "results = model(img)\n",
    "\n",
    "# Results\n",
    "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGH0ZjkGjejy"
   },
   "outputs": [],
   "source": [
    "# YOLOv5 CI\n",
    "%%shell\n",
    "rm -rf runs  # remove runs/\n",
    "m=yolov5n  # official weights\n",
    "b=runs/train/exp/weights/best  # best.pt checkpoint\n",
    "python train.py --imgsz 64 --batch 32 --weights $m.pt --cfg $m.yaml --epochs 1 --device 0  # train\n",
    "for d in 0 cpu; do  # devices\n",
    "  for w in $m $b; do  # weights\n",
    "    python val.py --imgsz 64 --batch 32 --weights $w.pt --device $d  # val\n",
    "    python detect.py --imgsz 64 --weights $w.pt --device $d  # detect\n",
    "  done\n",
    "done\n",
    "python hubconf.py --model $m  # hub\n",
    "python models/tf.py --weights $m.pt  # build TF model\n",
    "python models/yolo.py --cfg $m.yaml  # build PyTorch model\n",
    "python export.py --weights $m.pt --img 64 --include torchscript  # export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcKoSIK2WSzj"
   },
   "outputs": [],
   "source": [
    "# Reproduce\n",
    "for x in (f'yolov5{x}' for x in 'nsmlx'):\n",
    "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --task speed  # speed\n",
    "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.001 --iou 0.65  # mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gogI-kwi3Tye"
   },
   "outputs": [],
   "source": [
    "# Profile\n",
    "from utils.torch_utils import profile\n",
    "\n",
    "m1 = lambda x: x * torch.sigmoid(x)\n",
    "m2 = torch.nn.SiLU()\n",
    "results = profile(input=torch.randn(16, 3, 640, 640), ops=[m1, m2], n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSgFCAcMbk1R"
   },
   "outputs": [],
   "source": [
    "# VOC\n",
    "for b, m in zip([64, 64, 64, 32, 16], [f'yolov5{x}' for x in 'nsmlx']):  # batch, model\n",
    "  !python train.py --batch {b} --weights {m}.pt --data VOC.yaml --epochs 50 --img 512 --hyp hyp.VOC.yaml --project VOC --name {m} --cache"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "YOLOv5 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dbce99bb6184238842cbec0587d564a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "102e1deda239436fa72751c58202fa0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fd4431ced6c42368e18424912b877e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91ff5f93f2a24c5790ab29e347965946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9aeff9f1780b45f892422fdc96e56913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdd709c4f40941bea1b2053523c9fac8",
      "max": 818322941,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a1ef2d8de2b741c78ca5d938e2ddbcdf",
      "value": 818322941
     }
    },
    "a1ef2d8de2b741c78ca5d938e2ddbcdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf55a7c71d074d3fa88b10b997820825": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0dbce99bb6184238842cbec0587d564a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_91ff5f93f2a24c5790ab29e347965946",
      "value": " 780M/780M [01:10&lt;00:00, 10.5MB/s]"
     }
    },
    "c31d2039ccf74c22b67841f4877d1186": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4bba1727c714d94ad58a72bffa07c4c",
       "IPY_MODEL_9aeff9f1780b45f892422fdc96e56913",
       "IPY_MODEL_bf55a7c71d074d3fa88b10b997820825"
      ],
      "layout": "IPY_MODEL_d8b66044e2fb4f5b916696834d880c81"
     }
    },
    "cdd709c4f40941bea1b2053523c9fac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4bba1727c714d94ad58a72bffa07c4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_102e1deda239436fa72751c58202fa0f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4fd4431ced6c42368e18424912b877e4",
      "value": "100%"
     }
    },
    "d8b66044e2fb4f5b916696834d880c81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
